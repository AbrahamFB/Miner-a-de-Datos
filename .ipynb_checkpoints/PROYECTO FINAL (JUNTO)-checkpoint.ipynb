{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # Carga de librerías\n",
    "# \n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action = \"ignore\", category = FutureWarning) #Ignorar error de clase o versión\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import seaborn as sb\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import tree\n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import random\n",
    "import decimal\n",
    "import sklearn\n",
    "import yellowbrick\n",
    "\n",
    "\n",
    "from yellowbrick.features import Rank1D\n",
    "from yellowbrick.features import Rank2D\n",
    "from yellowbrick.features import PCA\n",
    "from yellowbrick.cluster.elbow import kelbow_visualizer\n",
    "from yellowbrick.cluster import InterclusterDistance\n",
    "from yellowbrick.target import FeatureCorrelation\n",
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "from yellowbrick.classifier import ClassPredictionError\n",
    "\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "print(\"Ingresa el nombre del archivo a leer con extensión .txt\")\n",
    "archivo = input()\n",
    "archivo = archivo + \".txt\"\n",
    "#SI\n",
    "#data385Attrib\n",
    "#cre300\n",
    "#Slice409\n",
    "\n",
    "\n",
    "# # Carga de datos\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "#Solo carga y lectura de los parámetros del conjunto de datos\n",
    "df = pd.read_csv(archivo, sep = \" \", header = None, names = [\"a\", \"b\", \"c\"])\n",
    "Elem = df[\"a\"][0]\n",
    "Attr = df[\"a\"][1]\n",
    "NumClas = df[\"a\"][2]\n",
    "print(\"Número de Elementos: \")\n",
    "print(Elem)\n",
    "print(\"Número de Atributos: \")\n",
    "print(Attr)\n",
    "print(\"Número de Clases: \")\n",
    "print(NumClas)\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "#Cargar y lectura total de los datos del conjunto\n",
    "df2 = pd.read_table(archivo, header = None, sep = \",\",skiprows = 3)\n",
    "print(df2)\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "#Número de Atributos\n",
    "numAttri = len(df2.columns) #o =Attr\n",
    "print(\"Número de Atributos:\")\n",
    "numAttri1 = numAttri-1\n",
    "print(numAttri1)\n",
    "numclas = NumClas\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# # Algoritmos de Machine Learning\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "# # División de la matriz del Conjunto de Datos en 2 partes\n",
    "# \n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "#Clasificadores con datos puros*\n",
    "#Separo todos los datos con las características y los resultados\n",
    "X = np.array(df2.drop([numAttri1], 1))\n",
    "y = np.array(df2[numAttri1])\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "print(\"Ingresa la proporción del conjunto de datos (debe estar entre 0.0 y 1.0 )\")\n",
    "proporcion = input()\n",
    "proporcion = float(proporcion)\n",
    "#0.2\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "#Separo los datos de \"train\" en entrenamiento y prueba para testear los clasificadores\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = proporcion)\n",
    "deTr = format(X_train.shape[0])\n",
    "deTe = format(X_test.shape[0])\n",
    "print(\"Datos para Entrenamiento\")\n",
    "print(deTr)\n",
    "print(\"Datos para prueba\")\n",
    "print(deTe)\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "#Escalado de funciones\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "#Asignación del número de componentes\n",
    "print(\"Ingresa número de componentes\")\n",
    "numComp = input()\n",
    "numComp = int(numComp)\n",
    "#2\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "#Pequeña muestra de la gráfica de PCA, más adelante es la definitiva*\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "pca = PCA(n_components = numComp)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# # Análisis de Datos\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "print(\"Información del Conjunto de Datos\")\n",
    "print(df2.info())\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "print(\"Descripción del Conjunto de Datos:\")\n",
    "print(df2.describe())\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "#Número de Atributos\n",
    "numAttri = len(df2.columns)\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "print(\"Distribución de atributos:\")\n",
    "print(df2.groupby(df2.iloc[:, numAttri1].values).size())\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "#Colores Random\n",
    "number_of_colors = 8\n",
    "\n",
    "color1 = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n",
    "             for i in range(number_of_colors)]\n",
    "\n",
    "\n",
    "# # Datos en las matrices\n",
    "# \n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "print(\"Conjunto de elementos\")\n",
    "print(X)\n",
    "\n",
    "print(\"\\nClases\")\n",
    "print(y)\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# # Normalización\n",
    "# \n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "#Apliqué una transformación de los datos para poder aplicar la distribución normal\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "\n",
    "\n",
    "# # Cálculo de autovectores y autovalores.\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "# Calculé la matriz de covarianza\n",
    "print(\"NumPy Matriz de covarianza: \\n%s\"\n",
    "      %np.cov(X_std.T))\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "# Valor propio y Vector Propio de la matriz\n",
    "covMat = np.cov(X_std.T)\n",
    "\n",
    "propiVal, propiVec = np.linalg.eig(covMat)\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "\n",
    "print(\"Vectores propios \\n%s\" %propiVec)\n",
    "\n",
    "print(\"\\nValores propios \\n%s\" %propiVal)\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "#  Hice una lista de parejas (Vector Propio, Valor Propio) \n",
    "propiPares = [(np.abs(\n",
    "                propiVal[i]),\n",
    "                propiVec[:, i])\n",
    "                for i in range(len(propiVal)\n",
    "             )]\n",
    "\n",
    "propiPares.sort(key = lambda x: x[0], reverse = True)\n",
    "\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "\n",
    "# Muestro la lista de autovalores en orden Descendente\n",
    "print(\"Autovalores en orden descendente: \")\n",
    "for i in propiPares:\n",
    "    print(i[0])\n",
    "    \n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# # Seleccioné los Vectores Propios correspondientes a las componentes principales\n",
    "# \n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "# Valores Propios, calculé la varianza explicada\n",
    "total = sum(propiVal)\n",
    "varExp = [(i / total) * 1 for i in sorted(propiVal, reverse = True)]\n",
    "cumVarExp = np.cumsum(varExp)\n",
    "\n",
    "# Varianza explicada por cada Valor Propio, y la acumulada\n",
    "with plt.style.context(\"fivethirtyeight\"):\n",
    "    plt.figure(figsize=(20, 8))    \n",
    "    #plt.figure(figsize=(numAttri1, 8))\n",
    "    plt.xlabel(\"Componentes\")\n",
    "    plt.ylabel(\"Radio de Varianza Explicada\")\n",
    "    plt.title(\"Varianza individual explicada\")\n",
    "    plt.bar(range(numAttri1), np.real(varExp), align = \"center\", color = color1, ecolor = \"black\")\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "\n",
    "# Varianza explicada por cada Valor Propio, y la acumulada\n",
    "total = sum(propiVal)\n",
    "varExp = [(i / total) * 1 for i in sorted(propiVal, reverse = True)]\n",
    "cum_var_exp = np.cumsum(varExp)\n",
    "\n",
    "# Varianza explicada por cada autovalor, y la acumulada\n",
    "with plt.style.context(\"fivethirtyeight\"):\n",
    "    plt.figure(figsize = (20, 10))   \n",
    "#    plt.figure(figsize = (numAttri1, 10))\n",
    "    #plt.show()\n",
    "    \n",
    "    plt.step(range(numAttri1), np.real(cum_var_exp), where = \"mid\", linestyle = \":\")\n",
    "    plt.ylabel(\"Radio de Varianza Explicada\")\n",
    "    plt.xlabel(\"Componentes\")\n",
    "    plt.title(\"Varianza explicada acumulada\")\n",
    "    plt.tight_layout()\n",
    "    \n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# # Datos Puros.\n",
    "# \n",
    "\n",
    "# In[27]:\n",
    "\n",
    "\n",
    "#Generé la matríz a partir de los pares Vector Propio y un Vector Propio\n",
    "matriz_PCA = np.hstack((propiPares[0][1].reshape(numAttri1, 1),\n",
    "                        propiPares[1][1].reshape(numAttri1, 1)\n",
    "                       ))\n",
    "\n",
    "Y = X_std.dot(matriz_PCA)\n",
    "Y = np.real(Y)\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "\n",
    "#Datos Puros* del Conjunto\n",
    "visualizer = PCA(scale = True, proj_features = True)\n",
    "visualizer.fit_transform(X, y)\n",
    "visualizer.show()\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "#Datos Puros* del Conjunto\n",
    "visualizer = PCA(scale = True, proj_features = True, projection = 3)\n",
    "visualizer.fit_transform(X, y)\n",
    "visualizer.show()\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# # Datos sobre un espacio de dimensionalidad 2.\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "##wrange = range(0, int(NumClas))\n",
    "##with plt.style.context(\"seaborn-whitegrid\"):\n",
    "##    plt.figure(figsize=(20,10))    \n",
    "###    plt.figure(figsize=(numAttri1,10))\n",
    "##    for eti, colu in zip((wrange), color1):\n",
    "##        plt.scatter(Y[y == eti, 0],\n",
    "##                    Y[y == eti, 1],\n",
    "##                    c = colu,\n",
    "##                    label = eti)\n",
    "##    plt.xlabel(\"Componente Principal 1\")\n",
    "##    plt.ylabel(\"Componente Principal 2\")\n",
    "##    plt.legend(loc = \"lower left\")\n",
    "##    plt.tight_layout()\n",
    "##    plt.show()\n",
    "\n",
    "\n",
    "# In[31]:\n",
    "\n",
    "\n",
    "#Asignar valores de los N componentes - Entrenamiento* \n",
    "principalDf = pd.DataFrame(data = X_train\n",
    "             , columns = [\"Componente Principal 1\", \"Componente Principal 2\"])\n",
    "finalDf = pd.concat([principalDf, df2[[numAttri1]]], axis = 1)\n",
    "\n",
    "\n",
    "# In[32]:\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (20,15))\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "ax.set_xlabel(\"Componente Principal 1\", fontsize = 15)\n",
    "ax.set_ylabel(\"Componente Principal 2\", fontsize = 15)\n",
    "ax.set_title(\"PCA de {} Componentes - Entrenamiento\".format(numComp), fontsize = 20)\n",
    "\n",
    "targets = range(0, int(NumClas))\n",
    "\n",
    "for target, color in zip(targets, color1):\n",
    "    indicesToKeep = finalDf[numAttri1] == target\n",
    "    ax.scatter(finalDf.loc[indicesToKeep, \"Componente Principal 1\"]\n",
    "               , finalDf.loc[indicesToKeep, \"Componente Principal 2\"]\n",
    "               , c = color\n",
    "               , s = 40)\n",
    "    \n",
    "ax.legend(targets)\n",
    "ax.grid()\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[33]:\n",
    "\n",
    "\n",
    "#Asignar valores de los N componentes - Prueba* \n",
    "principalDfT = pd.DataFrame(data = X_test\n",
    "             , columns = [\"Componente Principal 1\", \"Componente Principal 2\"])\n",
    "finalDfT = pd.concat([principalDfT, df2[[numAttri1]]], axis = 1)\n",
    "\n",
    "\n",
    "# In[34]:\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize = (20,15))\n",
    "\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "ax.set_xlabel(\"Componente Principal 1\", fontsize = 15)\n",
    "ax.set_ylabel(\"Componente Principal 2\", fontsize = 15)\n",
    "ax.set_title(\"PCA de {} Componentes - Prueba\".format(numComp), fontsize = 20)\n",
    "\n",
    "targets = range(0, int(NumClas))\n",
    "\n",
    "for target, color in zip(targets, color1):\n",
    "    indicesToKeep = finalDfT[numAttri1] == target\n",
    "    ax.scatter(finalDfT.loc[indicesToKeep, \"Componente Principal 1\"]\n",
    "               , finalDfT.loc[indicesToKeep, \"Componente Principal 2\"]\n",
    "               , c = color\n",
    "               , s = 40)\n",
    "    \n",
    "ax.legend(targets)\n",
    "ax.grid()\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[35]:\n",
    "\n",
    "\n",
    "#FUNCIONES EXTRA\n",
    "\n",
    "\n",
    "# In[36]:\n",
    "\n",
    "\n",
    "#Daros Puros* del Conjunto\n",
    "print(\"K-Medias\")\n",
    "kelbow_visualizer(KMeans(random_state = 4), X, k = (2,10))\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "\n",
    "print(\"Número de grupos\")\n",
    "numGr = input()\n",
    "numGr = int(numGr)\n",
    "#7\n",
    "\n",
    "\n",
    "# In[38]:\n",
    "\n",
    "\n",
    "# Instanciar el modelo de agrupamiento y el visualizador\n",
    "model = KMeans(numGr)\n",
    "visualizer = InterclusterDistance(model)\n",
    "\n",
    "print(\"Mapas de distancia intercluster\")\n",
    "visualizer.fit(X)        # Ajustar los datos al visualizador\n",
    "visualizer.show()        # Finaliza y renderiza la figura\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[39]:\n",
    "\n",
    "\n",
    "###gráfico donde se puedan observar las relaciones entre variables y sus histogramas\n",
    "##\n",
    "##sns.pairplot(df2)\n",
    "##plt.show()\n",
    "#HABILITAR si desea ver la relación\n",
    "\n",
    "\n",
    "# In[40]:\n",
    "\n",
    "\n",
    "##sns.set(style=\"ticks\")\n",
    "##\n",
    "##g = sns.pairplot(df2, corner = True)\n",
    "#HABILITAR Para trazar múltiples distribuciones bivariadas por pares en un conjunto de datos\n",
    "\n",
    "\n",
    "# In[41]:\n",
    "\n",
    "\n",
    "##g = sns.pairplot(df2, kind = \"reg\")\n",
    "#HABILITAR Para trazar múltiples distribuciones bivariadas por pares en un conjunto de datos\n",
    "\n",
    "\n",
    "# # K Vecinos más Cercanos\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"\\033[;32m\"+\"\\n\\n--------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"K Vecinos más Cercanos\")\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[43]:\n",
    "\n",
    "\n",
    "print(\"Número de vecinos a usar: \")\n",
    "numV = input()\n",
    "numV = int(numV)\n",
    "#7\n",
    "\n",
    "\n",
    "# In[45]:\n",
    "\n",
    "\n",
    "#Algoritmo\n",
    "kvc = KNeighborsClassifier(n_neighbors = numV, metric = \"minkowski\") #La métrica predeterminada es minkowski, y con p = 2 es equivalente a la métrica euclidiana estándar\n",
    "\n",
    "\n",
    "# In[46]:\n",
    "\n",
    "\n",
    "print(\"Ingresa el número de pliegues: \")\n",
    "pliegues = input()\n",
    "pliegues = int(pliegues)\n",
    "#10\n",
    "\n",
    "\n",
    "# In[47]:\n",
    "\n",
    "\n",
    "#Rendimiento\n",
    "puntaje = cross_val_score(kvc, X, y, cv = pliegues, scoring = \"accuracy\")\n",
    "\n",
    "\n",
    "# In[48]:\n",
    "\n",
    "\n",
    "#Lo Entreno\n",
    "kvc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# In[49]:\n",
    "\n",
    "\n",
    "#Predicción\n",
    "y_pred = kvc.predict(X_test)\n",
    "y_predE = kvc.predict(X_train)\n",
    "\n",
    "\n",
    "# In[50]:\n",
    "\n",
    "\n",
    "predecir = cross_val_predict(kvc, X, y, cv = pliegues)\n",
    "matriz = confusion_matrix(y, predecir)\n",
    "print(\"Matriz de Confusión\")\n",
    "print(matriz)\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[51]:\n",
    "\n",
    "\n",
    "predicciones = []\n",
    "for f in  predecir:\n",
    "    r = random.triangular(-.1, .1)\n",
    "    r = round(r, 3)\n",
    "    predicciones.append(f + r)\n",
    "\n",
    "\n",
    "# In[52]:\n",
    "\n",
    "\n",
    "real = pd.DataFrame(data = y, columns = [\"Real\"])\n",
    "clases = pd.DataFrame(data = y, columns = [\"Clases\"])\n",
    "predecidas = pd.DataFrame(data = predicciones, columns = [\"Predicción\"])\n",
    "matrix = pd.concat([real, predecidas, clases], axis = 1)\n",
    "\n",
    "sb.stripplot(x = \"Real\", y = \"Predicción\", data = matrix, jitter = .1, linewidth = 1)\n",
    "plt.show()\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[53]:\n",
    "\n",
    "\n",
    "print(\"Precisión K-Vecinos más Cercanos: \")\n",
    "print(str(np.mean(puntaje)*100) + \"%\")\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[54]:\n",
    "\n",
    "\n",
    "df_confusion1 = pd.crosstab(y_test, y_pred)\n",
    "df_confusion11 = pd.crosstab(y_train, y_predE)\n",
    "\n",
    "\n",
    "# In[55]:\n",
    "\n",
    "\n",
    "df_confusion1 = pd.crosstab(y_test, y_pred, rownames = [\"Prueba\"], colnames = [\"Predicción\"], margins = True)\n",
    "df_confusion11 = pd.crosstab(y_train, y_predE, rownames = [\"Entrenamiento\"], colnames = [\"Predicción\"], margins = True)\n",
    "\n",
    "\n",
    "# In[56]:\n",
    "\n",
    "\n",
    "df_conf_norm = df_confusion1 / df_confusion1.sum(axis = 1)\n",
    "df_conf_norm11 = df_confusion11 / df_confusion1.sum(axis = 1)\n",
    "\n",
    "\n",
    "# In[57]:\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(df_confusion1, title = \"Matriz de Confusión\", cmap = plt.cm.gray_r):\n",
    "    plt.matshow(df_confusion1, cmap = cmap) # imshow\n",
    "\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(df_confusion1.columns))\n",
    "    plt.xticks(tick_marks, df_confusion1.columns, rotation = 45)\n",
    "    plt.yticks(tick_marks, df_confusion1.index)\n",
    "\n",
    "    plt.ylabel(df_confusion1.index.name)\n",
    "    plt.xlabel(df_confusion1.columns.name)\n",
    "    \n",
    "def plot_confusion_matrix1(df_confusion11, title = \"Matriz de Confusión\", cmap = plt.cm.gray_r):\n",
    "    plt.matshow(df_confusion11, cmap = cmap) # imshow\n",
    "\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(df_confusion11.columns))\n",
    "    plt.xticks(tick_marks, df_confusion11.columns, rotation = 45)\n",
    "    plt.yticks(tick_marks, df_confusion11.index)\n",
    "\n",
    "    plt.ylabel(df_confusion11.index.name)\n",
    "    plt.xlabel(df_confusion11.columns.name)\n",
    "\n",
    "\n",
    "# In[58]:\n",
    "\n",
    "\n",
    "plot_confusion_matrix(df_confusion1)\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[59]:\n",
    "\n",
    "\n",
    "#Matriz de Confusión, para ver que tan bien o mal se clasificó\n",
    "matrizKV = confusion_matrix(y_test, y_pred)\n",
    "print(\"Matriz de Confusión - Prueba:\")\n",
    "\n",
    "print(matrizKV)\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[60]:\n",
    "\n",
    "\n",
    "#Precisión Prueba\n",
    "preKVCP = format(kvc.score(X_test, y_test))\n",
    "preKVCP = (float(preKVCP)*100)\n",
    "\n",
    "print(\"Precisión K-Vecinos más Cercanos: \")\n",
    "print(str(preKVCP) + \"%\")\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[61]:\n",
    "\n",
    "\n",
    "plot_confusion_matrix1(df_confusion11)\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[62]:\n",
    "\n",
    "\n",
    "#Matriz de Confusión, para ver que tan bien o mal se clasificó\n",
    "matrizKV = confusion_matrix(y_train, y_predE)\n",
    "print(\"Matriz de Confusión - Entrenamiento:\")\n",
    "\n",
    "print(matrizKV)\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[63]:\n",
    "\n",
    "\n",
    "#Precisión Entrenamiento\n",
    "preKVCE = format(kvc.score(X_test, y_test))\n",
    "preKVCE = (float(preKVCE)*100)\n",
    "\n",
    "print(\"Precisión K-Vecinos más Cercanos: \")\n",
    "print(str(preKVCE) + \"%\")\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[64]:\n",
    "\n",
    "\n",
    "#Implementando Entrenamiento y Prueba\n",
    "classes = range(0, int(NumClas))\n",
    "\n",
    "cm = ConfusionMatrix(kvc, classes = classes)\n",
    "\n",
    "cm.fit(X_train, y_train)\n",
    "cm.score(X_test, y_test)\n",
    "\n",
    "cm.show()\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[143]:\n",
    "\n",
    "\n",
    "classes = range(0, int(NumClas))\n",
    "\n",
    "# Instanciar el modelo de clasificación y el visualizador\n",
    "visualizer = ClassPredictionError(\n",
    "    kvc, classes = classes\n",
    ")\n",
    "\n",
    "# Ajustar los datos de entrenamiento al visualizador\n",
    "visualizer.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el modelo en los datos de prueba\n",
    "visualizer.score(X_test, y_test)\n",
    "\n",
    "# Dibujar visualización\n",
    "visualizer.show()\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[65]:\n",
    "\n",
    "\n",
    "#Validación Cruzada Prueba\n",
    "precisionKVCP = sklearn.model_selection.cross_val_score(estimator = kvc,\n",
    "                                            X = X_test, y = y_test,\n",
    "                                            cv = 2, n_jobs = -1)\n",
    "\n",
    "print(\"Precisiones: {}\\n\".format(precisionKVCP))\n",
    "print(\"Precisión promedio: {0: .3f} +/- {1: .3f}\".format(np.mean(precisionKVCP),\n",
    "                                          np.std(precisionKVCP)))\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[66]:\n",
    "\n",
    "\n",
    "#Validación Cruzada Entrenamiento\n",
    "precisionKVCE = sklearn.model_selection.cross_val_score(estimator = kvc,\n",
    "                                            X = X_train, y = y_train,\n",
    "                                            cv = pliegues, n_jobs = -1)\n",
    "\n",
    "print(\"Precisiones: {}\\n\".format(precisionKVCE))\n",
    "print(\"Precisión promedio: {0: .3f} +/- {1: .3f}\".format(np.mean(precisionKVCE),\n",
    "                                          np.std(precisionKVCE)))\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[67]:\n",
    "\n",
    "\n",
    "# Grafico de ajuste de K Vecinos más Cercanos\n",
    "k_range = range(1, numAttri1)\n",
    "eval_prec = []\n",
    "train_prec = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_prec.append(knn.score(X_train, y_train))\n",
    "    eval_prec.append(knn.score(X_test, y_test))\n",
    "    \n",
    "# Resultados.\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "plt.plot(train_prec, color=\"green\", label=\"Entrenamiento\")\n",
    "plt.plot(eval_prec, color=\"cyan\", label=\"Prueba\")\n",
    "plt.title(\"Ajuste K Vecinos más Cercanos\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Número de nodos\")\n",
    "plt.ylabel(\"Precisión\")\n",
    "plt.show()\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[68]:\n",
    "\n",
    "\n",
    "#Validación Cruzada Entrenamiento\n",
    "precisionKVCE = sklearn.model_selection.cross_val_score(estimator = kvc,\n",
    "                                            X = X_train, y = y_train,\n",
    "                                            cv = pliegues, n_jobs = -1)\n",
    "# Grafico de ajuste de K Vecinos más Cercanos\n",
    "k_range = range(1, numAttri1)\n",
    "eval_prec = []\n",
    "train_prec = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    train_prec.append(knn.score(X_train, y_train))\n",
    "    eval_prec.append(knn.score(X_test, y_test))\n",
    "    \n",
    "# Resultados.\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "plt.plot(k_range, train_prec, color = \"green\", label = \"Entrenamiento\")\n",
    "plt.plot(k_range, eval_prec, color = \"cyan\", label = \"Prueba\")\n",
    "plt.plot(precisionKVCE, color = \"pink\", label = \"Kfold\")\n",
    "\n",
    "plt.title(\"Ajuste K Vecinos más Cercanos\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Precisión\")\n",
    "plt.xlabel(\"Número de ejemplos\")\n",
    "plt.show()\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[69]:\n",
    "\n",
    "\n",
    "#Precisión del modelo - Prueba\n",
    "print(\"Precisión K Vecinos Más Cercanos - Prueba\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[70]:\n",
    "\n",
    "\n",
    "#Precisión del modelo - Entrenamiento\n",
    "print(\"Precisión K Vecinos Más Cercanos - Entrenamiento\")\n",
    "print(classification_report(y_train, y_predE))\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[71]:\n",
    "\n",
    "\n",
    "#Elegir el mejor valor de k\n",
    "k_range = range(1, numAttri1)\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    scores.append(knn.score(X_test, y_test))\n",
    "plt.figure()\n",
    "plt.title(\"Elegir el mejor valor de k\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Precisión\")\n",
    "plt.scatter(k_range, scores)\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[72]:\n",
    "\n",
    "\n",
    "# Curvas de aprendizaje\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator = kvc,\n",
    "                        X = X_train, y = y_train, \n",
    "                        train_sizes = np.linspace(0.1, 1.0, 10), cv = pliegues,\n",
    "                        n_jobs = -1)\n",
    "\n",
    "train_mean = np.mean(train_scores, axis = 1)\n",
    "train_std = np.std(train_scores, axis = 1)\n",
    "\n",
    "test_mean = np.mean(test_scores, axis = 1)\n",
    "test_std = np.std(test_scores, axis = 1)\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[73]:\n",
    "\n",
    "\n",
    "# Graficando las curvas\n",
    "plt.subplots(figsize=(20, 15))\n",
    "\n",
    "plt.plot(train_sizes, train_mean, color = \"g\", marker = \"o\", markersize = 5,\n",
    "         label = \"Entrenamiento\")\n",
    "plt.fill_between(train_sizes, train_mean + train_std, \n",
    "                 train_mean - train_std, alpha = 0.1, color = \"g\")\n",
    "\n",
    "plt.plot(train_sizes, test_mean, color = \"b\", linestyle = \"--\", \n",
    "         marker = \"s\", markersize = 5, label = \"Prueba\")\n",
    "plt.fill_between(train_sizes, test_mean + test_std, \n",
    "                 test_mean - test_std, alpha = 0.1, color = \"b\")\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.title(\"Curva de aprendizaje - K Vecinos más Cercanos\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.xlabel(\"Cantidad de Ejemplos de Entrenamiento\")\n",
    "plt.ylabel(\"Precisión\")\n",
    "plt.show()\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# # Navie Bayes\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "print(\"\\033[;36m\"+\"\\n\\n--------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"Navie Bayes\")\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[75]:\n",
    "\n",
    "\n",
    "#Algoritmo\n",
    "gnb = GaussianNB()\n",
    "\n",
    "\n",
    "# In[76]:\n",
    "\n",
    "\n",
    "puntuación = cross_val_score(gnb, X, y, cv = pliegues, scoring = \"accuracy\")\n",
    "\n",
    "\n",
    "# In[77]:\n",
    "\n",
    "\n",
    "#Lo Entreno\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# In[78]:\n",
    "\n",
    "\n",
    "#Predicción\n",
    "y_pred2 = gnb.predict(X_test)\n",
    "y_pred22 = gnb.predict(X_train)\n",
    "\n",
    "\n",
    "# In[79]:\n",
    "\n",
    "\n",
    "cvp = cross_val_predict(gnb, X, y, cv = pliegues)\n",
    "matriz = confusion_matrix(y, cvp)\n",
    "print(\"Matriz de Confusión\")\n",
    "print(matriz)\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[80]:\n",
    "\n",
    "\n",
    "predicciones = []\n",
    "for f in  cvp:\n",
    "    r = random.triangular(-.1, .1)\n",
    "    r = round(r, 3)\n",
    "    predicciones.append(f + r)\n",
    "\n",
    "\n",
    "# In[81]:\n",
    "\n",
    "\n",
    "clas = pd.DataFrame(data = y, columns = [\"Clases\"])\n",
    "real = pd.DataFrame(data = y, columns = [\"Real\"])\n",
    "prede = pd.DataFrame(data = predicciones, columns = [\"Predicción\"])\n",
    "concatenado = pd.concat([real, prede, clas], axis = 1)\n",
    "\n",
    "sb.stripplot(x = \"Real\", y = \"Predicción\", data = concatenado, jitter = .1, linewidth = 1)\n",
    "plt.show()\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[82]:\n",
    "\n",
    "\n",
    "print(\"Precisión Navie Bayes: \")\n",
    "print(str(np.mean(puntuación)*100) + \"%\")\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[83]:\n",
    "\n",
    "\n",
    "df_confusion2 = pd.crosstab(y_test, y_pred2)\n",
    "df_confusion22 = pd.crosstab(y_train, y_pred22)\n",
    "\n",
    "\n",
    "# In[84]:\n",
    "\n",
    "\n",
    "df_confusion2 = pd.crosstab(y_test, y_pred2, rownames = [\"Prueba\"], colnames = [\"Predicción\"], margins = True)\n",
    "df_confusion22 = pd.crosstab(y_train, y_pred22, rownames = [\"Entrenamiento\"], colnames = [\"Predicción\"], margins = True)\n",
    "\n",
    "\n",
    "# In[85]:\n",
    "\n",
    "\n",
    "df_conf_norm2 = df_confusion2 / df_confusion2.sum(axis = 1)\n",
    "df_conf_norm22 = df_confusion22 / df_confusion22.sum(axis = 1)\n",
    "\n",
    "\n",
    "# In[86]:\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(df_confusion2, title = \"Matriz de Confusión\", cmap = plt.cm.gray_r):\n",
    "    plt.matshow(df_confusion2, cmap = cmap) # imshow\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(df_confusion2.columns))\n",
    "    plt.xticks(tick_marks, df_confusion2.columns, rotation = 45)\n",
    "    plt.yticks(tick_marks, df_confusion2.index)\n",
    "    plt.ylabel(df_confusion2.index.name)\n",
    "    plt.xlabel(df_confusion2.columns.name)\n",
    "\n",
    "def plot_confusion_matrix2(df_confusion22, title = \"Matriz de Confusión\", cmap = plt.cm.gray_r):\n",
    "    plt.matshow(df_confusion22, cmap = cmap) # imshow\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(df_confusion22.columns))\n",
    "    plt.xticks(tick_marks, df_confusion22.columns, rotation = 45)\n",
    "    plt.yticks(tick_marks, df_confusion22.index)\n",
    "    plt.ylabel(df_confusion22.index.name)\n",
    "    plt.xlabel(df_confusion22.columns.name)\n",
    "\n",
    "\n",
    "# In[87]:\n",
    "\n",
    "\n",
    "plot_confusion_matrix(df_confusion2)\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[85]:\n",
    "\n",
    "\n",
    "#Matriz de Confusión, para ver que tan bien o mal se clasificó\n",
    "matrizGNB = confusion_matrix(y_test, y_pred2)\n",
    "print(\"Matriz de Confusión - Prueba:\")\n",
    "print(matrizGNB)\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[89]:\n",
    "\n",
    "\n",
    "#Precisión Prueba\n",
    "preGNBP = format(gnb.score(X_test, y_test))\n",
    "preGNBP = float(preGNBP)*100\n",
    "print(\"Precisión Navie Bayes: \")\n",
    "print(str(preGNBP) + \"%\")\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[90]:\n",
    "\n",
    "\n",
    "plot_confusion_matrix2(df_confusion22)\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[91]:\n",
    "\n",
    "\n",
    "#Matriz de Confusión, para ver que tan bien o mal se clasificó\n",
    "matrizGNB = confusion_matrix(y_train, y_pred22)\n",
    "print(\"Matriz de Confusión - Entrenamiento:\")\n",
    "\n",
    "print(matrizGNB)\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[93]:\n",
    "\n",
    "\n",
    "#Precisión Entrenamiento\n",
    "preGNBE = format(gnb.score(X_train, y_train))\n",
    "preGNBE = float(preGNBE)*100\n",
    "\n",
    "print(\"Precisión Navie Bayes: \")\n",
    "print(str(preGNBE) + \"%\")\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[94]:\n",
    "\n",
    "\n",
    "cm = ConfusionMatrix(gnb, classes = classes)\n",
    "\n",
    "cm.fit(X_train, y_train)\n",
    "cm.score(X_test, y_test)\n",
    "\n",
    "cm.show()\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[145]:\n",
    "\n",
    "\n",
    "# Instanciar el modelo de clasificación y el visualizador\n",
    "visualizer = ClassPredictionError(\n",
    "    gnb, classes = classes\n",
    ")\n",
    "\n",
    "# Ajustar los datos de entrenamiento al visualizador\n",
    "visualizer.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el modelo en los datos de prueba\n",
    "visualizer.score(X_test, y_test)\n",
    "\n",
    "# Dibujar visualización\n",
    "visualizer.show()\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[96]:\n",
    "\n",
    "\n",
    "print(\"Validación Cruzada - Prueba\")\n",
    "precision = sklearn.model_selection.cross_val_score(estimator = gnb,\n",
    "                                            X = X_test, y = y_test,\n",
    "                                            cv = 2, n_jobs = -1)\n",
    "\n",
    "print(\"Precisiones: {}\\n\".format(precision))\n",
    "print(\"Precisión promedio: {0: .3f} +/- {1: .3f}\".format(np.mean(precision),\n",
    "                                          np.std(precision)))\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[97]:\n",
    "\n",
    "\n",
    "print(\"Validación Cruzada - Entrenamiento\")\n",
    "precision = sklearn.model_selection.cross_val_score(estimator = gnb,\n",
    "                                            X = X_train, y = y_train,\n",
    "                                            cv = pliegues, n_jobs = -1)\n",
    "\n",
    "print(\"Precisiones: {}\\n\".format(precision))\n",
    "print(\"Precisión promedio: {0: .3f} +/- {1: .3f}\".format(np.mean(precision),\n",
    "                                          np.std(precision)))\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[98]:\n",
    "\n",
    "\n",
    "# Grafico de ajuste de Navie Bayes\n",
    "k_range = range(1, numAttri1)\n",
    "eval_prec = []\n",
    "train_prec = []\n",
    "for k in k_range:\n",
    "    train_prec.append(gnb.score(X_train, y_train))\n",
    "    eval_prec.append(gnb.score(X_test, y_test))\n",
    "    \n",
    "# Resultados.\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "plt.plot(train_prec, color = \"green\", label = \"Entrenamiento\")\n",
    "plt.plot(eval_prec, color = \"cyan\", label = \"Prueba\")\n",
    "plt.title(\"Ajuste Navie Bayes\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Número de nodos\")\n",
    "plt.ylabel(\"Precisión\")\n",
    "plt.show()\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[98]:\n",
    "\n",
    "\n",
    "#Validación Cruzada Navie Bayes\n",
    "precisionGNBE = sklearn.model_selection.cross_val_score(estimator = gnb,\n",
    "                                            X = X_train, y = y_train,\n",
    "                                            cv = pliegues, n_jobs = -1)                                                        \n",
    "\n",
    "# Grafico de ajuste de Navie Bayes\n",
    "k_range = range(1, numAttri1)\n",
    "eval_prec = []\n",
    "train_prec = []\n",
    "for k in k_range:\n",
    "    train_prec.append(gnb.score(X_train, y_train))\n",
    "    eval_prec.append(gnb.score(X_test, y_test))\n",
    "    #precision((X_test, y_test))\n",
    "# Resultados.\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "plt.plot(k_range, train_prec, color = \"green\", label = \"Entrenamiento\")\n",
    "plt.plot(k_range, eval_prec, color = \"cyan\", label = \"Prueba\")\n",
    "plt.plot(precisionGNBE, color = \"pink\", label = \"Kfold\")\n",
    "\n",
    "plt.title(\"Ajuste Navie Bayes\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Precisión\")\n",
    "plt.xlabel(\"Número de ejemplos\")\n",
    "plt.show()\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[99]:\n",
    "\n",
    "\n",
    "#Precisión del modelo - Prueba\n",
    "print(\"Precisión Navie Bayes - Prueba\")\n",
    "print(classification_report(y_test, y_pred2))\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "#Precisión del modelo - Entrenamiento\n",
    "print(\"Precisión Navie Bayes - Entrenamiento\")\n",
    "print(classification_report(y_train, y_pred22))\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[101]:\n",
    "\n",
    "\n",
    "# Curvas de aprendizaje\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator = gnb,\n",
    "                        X = X_train, y = y_train, \n",
    "                        train_sizes = np.linspace(0.1, 1.0, 10), cv = pliegues,\n",
    "                        n_jobs = -1)\n",
    "\n",
    "train_mean = np.mean(train_scores, axis = 1)\n",
    "train_std = np.std(train_scores, axis = 1)\n",
    "\n",
    "test_mean = np.mean(test_scores, axis = 1)\n",
    "test_std = np.std(test_scores, axis = 1)\n",
    "\n",
    "\n",
    "# In[102]:\n",
    "\n",
    "\n",
    "# Graficando las curvas\n",
    "plt.subplots(figsize=(20, 15))\n",
    "\n",
    "plt.plot(train_sizes, train_mean, color = \"g\", marker = \"o\", markersize = 5,\n",
    "         label = \"Entrenamiento\")\n",
    "plt.fill_between(train_sizes, train_mean + train_std, \n",
    "                 train_mean - train_std, alpha = 0.1, color = \"g\")\n",
    "\n",
    "plt.plot(train_sizes, test_mean, color = \"b\", linestyle = \"--\", \n",
    "         marker = \"s\", markersize = 5, label = \"Prueba\")\n",
    "plt.fill_between(train_sizes, test_mean + test_std, \n",
    "                 test_mean - test_std, alpha = 0.1, color = \"b\")\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.title(\"Curva de aprendizaje - Navie Bayes\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.xlabel(\"Cantidad de Ejemplos de Entrenamiento\")\n",
    "plt.ylabel(\"Precisión\")\n",
    "plt.show()\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# # Árboles de Decisión Clasificación\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn import tree\n",
    "\n",
    "print(\"\\033[;31m\"+\"\\n\\n--------------------------------------------------------------------------------------------------------------------------------------------------------------------\")\n",
    "print(\"Árbol de Decisión Clasificación\")\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[104]:\n",
    "\n",
    "\n",
    "print(\"Ingresa la profundidad máxima del árbol: \")\n",
    "prof = input()\n",
    "prof = int(prof)\n",
    "#5\n",
    "\n",
    "\n",
    "# In[105]:\n",
    "\n",
    "\n",
    "print(\"Ingresa la función para medir la calidad de una división. Los criterios admitidos son 'gini' y 'entropy'.\")\n",
    "criterio = input()\n",
    "#entropy\n",
    "#gini\n",
    "\n",
    "\n",
    "# In[107]:\n",
    "\n",
    "\n",
    "#Algoritmo\n",
    "ad = DecisionTreeClassifier(criterion = criterio, max_depth = prof)#Profundidad\n",
    "\n",
    "\n",
    "# In[108]:\n",
    "\n",
    "\n",
    "#Rendimiento\n",
    "puntaje = cross_val_score(ad, X, y, cv = pliegues, scoring = \"accuracy\")\n",
    "\n",
    "\n",
    "# In[109]:\n",
    "\n",
    "\n",
    "#Lo Entreno\n",
    "ad.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# In[110]:\n",
    "\n",
    "\n",
    "#Predicción\n",
    "y_pred3 = ad.predict(X_test)\n",
    "y_pred33 = ad.predict(X_train)\n",
    "\n",
    "\n",
    "# In[111]:\n",
    "\n",
    "\n",
    "predecir = cross_val_predict(ad, X, y, cv = pliegues)\n",
    "matriz = confusion_matrix(y, predecir)\n",
    "print(\"Matriz de Confusión\")\n",
    "print(matriz)\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[114]:\n",
    "\n",
    "\n",
    "predicciones = []\n",
    "for f in  predecir:\n",
    "    r= random.triangular(-.1, .1)\n",
    "    r = round(r, 3)\n",
    "    predicciones.append(f + r)\n",
    "\n",
    "\n",
    "# In[116]:\n",
    "\n",
    "\n",
    "real = pd.DataFrame(data = y, columns = [\"Real\"])\n",
    "clases = pd.DataFrame(data = y, columns = [\"Clases\"])\n",
    "predecidas = pd.DataFrame(data = predicciones, columns = [\"Predicción\"])\n",
    "matrix = pd.concat([real, predecidas, clases], axis = 1)\n",
    "\n",
    "sb.stripplot(x = \"Real\", y = \"Predicción\", data = matrix, jitter = .1, linewidth = 1)\n",
    "plt.show()\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[117]:\n",
    "\n",
    "\n",
    "print(\"Precisión Árbol de Decisión: \")\n",
    "print(str(np.mean(puntaje)*100) + \"%\")\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[118]:\n",
    "\n",
    "\n",
    "df_confusion3 = pd.crosstab(y_test, y_pred3)\n",
    "df_confusion33 = pd.crosstab(y_train, y_pred33)\n",
    "\n",
    "\n",
    "# In[119]:\n",
    "\n",
    "\n",
    "df_confusion3 = pd.crosstab(y_test, y_pred3, rownames = [\"Prueba\"], colnames = [\"Predicción\"], margins = True)\n",
    "df_confusion33 = pd.crosstab(y_train, y_pred33, rownames = [\"Entrenamiento\"], colnames = [\"Predicción\"], margins = True)\n",
    "\n",
    "\n",
    "# In[120]:\n",
    "\n",
    "\n",
    "df_conf_norm3 = df_confusion3 / df_confusion3.sum(axis = 1)\n",
    "df_conf_norm33 = df_confusion33 / df_confusion33.sum(axis = 1)\n",
    "\n",
    "\n",
    "# In[121]:\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(df_confusion3, title = \"Matriz de Confusión\", cmap = plt.cm.gray_r):\n",
    "    plt.matshow(df_confusion3, cmap = cmap) # imshow\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(df_confusion3.columns))\n",
    "    plt.xticks(tick_marks, df_confusion3.columns, rotation = 45)\n",
    "    plt.yticks(tick_marks, df_confusion3.index)\n",
    "    plt.ylabel(df_confusion3.index.name)\n",
    "    plt.xlabel(df_confusion3.columns.name)\n",
    "    \n",
    "def plot_confusion_matrix3(df_confusion33, title = \"Matriz de Confusión\", cmap = plt.cm.gray_r):\n",
    "    plt.matshow(df_confusion33, cmap = cmap) # imshow\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(df_confusion33.columns))\n",
    "    plt.xticks(tick_marks, df_confusion33.columns, rotation = 45)\n",
    "    plt.yticks(tick_marks, df_confusion33.index)\n",
    "    plt.ylabel(df_confusion33.index.name)\n",
    "    plt.xlabel(df_confusion33.columns.name)\n",
    "\n",
    "\n",
    "# In[122]:\n",
    "\n",
    "\n",
    "plot_confusion_matrix(df_confusion3)\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[123]:\n",
    "\n",
    "\n",
    "#Matriz de Confusión, para ver que tan bien o mal se clasificó\n",
    "matrizAD = confusion_matrix(y_test, y_pred3)\n",
    "print(\"Matriz de Confusión - Prueba:\")\n",
    "print(matrizAD)\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[125]:\n",
    "\n",
    "\n",
    "#Precisión Prueba\n",
    "preADP = precision_score(y_test, y_pred, average = \"weighted\")#Ponderado\n",
    "preADP = float(preADP)*100\n",
    "print(\"Precisión Árbol de Decisión:\")\n",
    "print(str(preADP) + \"%\")\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[126]:\n",
    "\n",
    "\n",
    "plot_confusion_matrix3(df_confusion33)\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[128]:\n",
    "\n",
    "\n",
    "#Matriz de Confusión, para ver que tan bien o mal se clasificó \n",
    "matrizAD = confusion_matrix(y_train, y_pred33)\n",
    "print(\"Matriz de Confusión - Entrenamiento:\")\n",
    "print(matrizAD)\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[130]:\n",
    "\n",
    "\n",
    "cm = ConfusionMatrix(ad, classes = classes)\n",
    "\n",
    "cm.fit(X_train, y_train)\n",
    "cm.score(X_test, y_test)\n",
    "\n",
    "cm.show()\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[144]:\n",
    "\n",
    "\n",
    "# Instanciar el modelo de clasificación y el visualizador\n",
    "visualizer = ClassPredictionError(\n",
    "    ad, classes = classes\n",
    ")\n",
    "\n",
    "# Ajustar los datos de entrenamiento al visualizador\n",
    "visualizer.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el modelo en los datos de prueba\n",
    "visualizer.score(X_test, y_test)\n",
    "\n",
    "# Dibujar visualización\n",
    "visualizer.show()\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[131]:\n",
    "\n",
    "\n",
    "#Validación Cruzada Prueba\n",
    "precisionADP = sklearn.model_selection.cross_val_score(estimator = ad,\n",
    "                                            X = X_test, y = y_test,\n",
    "                                            cv = 2, n_jobs = -1)\n",
    "\n",
    "print(\"Precisiones: {}\\n\".format(precisionADP))\n",
    "print(\"Precisión promedio: {0: .3f} +/- {1: .3f}\".format(np.mean(precisionADP),\n",
    "                                          np.std(precisionADP)))\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[132]:\n",
    "\n",
    "\n",
    "#Validación Cruzada Entrenamiento\n",
    "precisionADE = sklearn.model_selection.cross_val_score(estimator = ad,\n",
    "                                            X = X_train, y = y_train,\n",
    "                                            cv = pliegues, n_jobs = -1)\n",
    "\n",
    "print(\"Precisiones: {}\\n\".format(precisionADE))\n",
    "print(\"Precision promedio: {0: .3f} +/- {1: .3f}\".format(np.mean(precisionADE),\n",
    "                                          np.std(precisionADE)))\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[133]:\n",
    "\n",
    "\n",
    "# Gráfico de ajuste del Árbol de Decisión\n",
    "train_prec =  []\n",
    "eval_prec = []\n",
    "max_deep_list = list(range(1, numAttri1))\n",
    "\n",
    "for deep in max_deep_list:\n",
    "    arbol3 = DecisionTreeClassifier(criterion = criterio, max_depth = deep)\n",
    "    arbol3.fit(X_train, y_train)\n",
    "    train_prec.append(arbol3.score(X_train, y_train))\n",
    "    eval_prec.append(arbol3.score(X_test, y_test))\n",
    "\n",
    "# Resultados.\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "plt.plot(max_deep_list, train_prec, color = \"green\", label = \"Entrenamiento\")\n",
    "plt.plot(max_deep_list, eval_prec, color = \"cyan\", label = \"Prueba\")\n",
    "plt.title(\"Ajuste árbol de Decisión\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Precisión\")\n",
    "plt.xlabel(\"Número de nodos\")\n",
    "plt.show()\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[134]:\n",
    "\n",
    "\n",
    "#Validación Cruzada \n",
    "precisionADP = sklearn.model_selection.cross_val_score(estimator = ad,\n",
    "                                            X = X_train, y = y_train,\n",
    "                                            cv = pliegues, n_jobs = -1)\n",
    "\n",
    "# Gráfico de ajuste del Árbol de Decisión\n",
    "train_prec =  []\n",
    "eval_prec = []\n",
    "max_deep_list = list(range(1, numAttri1))\n",
    "\n",
    "for deep in max_deep_list:\n",
    "    arbol3 = DecisionTreeClassifier(criterion  = criterio, max_depth = deep)\n",
    "    arbol3.fit(X_train, y_train)\n",
    "    train_prec.append(arbol3.score(X_train, y_train))\n",
    "    eval_prec.append(arbol3.score(X_test, y_test))\n",
    "\n",
    "# Resultados.\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "plt.plot(max_deep_list, train_prec, color = \"green\", label = \"Entrenamiento\")\n",
    "plt.plot(max_deep_list, eval_prec, color = \"cyan\", label = \"Prueba\")\n",
    "plt.plot(precisionADP, color = \"pink\", label = \"Kfold\")\n",
    "\n",
    "plt.title(\"Ajuste árbol de Decisión\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Precisión\")\n",
    "plt.xlabel(\"Número de ejemplos\")\n",
    "plt.show()\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[135]:\n",
    "\n",
    "\n",
    "print(\"Precisión Árbol de Decisión - Prueba\")\n",
    "print(classification_report(y_test, y_pred3))\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[136]:\n",
    "\n",
    "\n",
    "print(\"Precisión Árbol de Decisión - Entrenamiento\")\n",
    "print(classification_report(y_train, y_pred33))\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[137]:\n",
    "\n",
    "\n",
    "# Curvas de aprendizaje\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator = ad,\n",
    "                        X = X_train, y = y_train, \n",
    "                        train_sizes = np.linspace(0.1, 1.0, 10), cv = pliegues,\n",
    "                        n_jobs = -1)\n",
    "\n",
    "train_mean = np.mean(train_scores, axis = 1)\n",
    "train_std = np.std(train_scores, axis = 1)\n",
    "\n",
    "test_mean = np.mean(test_scores, axis = 1)\n",
    "test_std = np.std(test_scores, axis = 1)\n",
    "\n",
    "\n",
    "# In[138]:\n",
    "\n",
    "\n",
    "# Graficando las curvas\n",
    "plt.subplots(figsize=(20, 15))\n",
    "\n",
    "plt.plot(train_sizes, train_mean, color = \"g\", marker = \"o\", markersize = 5,\n",
    "         label = \"Entrenamiento\")\n",
    "plt.fill_between(train_sizes, train_mean + train_std, \n",
    "                 train_mean - train_std, alpha = 0.1, color='g')\n",
    "\n",
    "plt.plot(train_sizes, test_mean, color = \"b\", linestyle = \"--\", \n",
    "         marker = \"s\", markersize = 5, label = \"Prueba\")\n",
    "plt.fill_between(train_sizes, test_mean + test_std, \n",
    "                 test_mean - test_std, alpha = 0.1, color = \"b\")\n",
    "\n",
    "plt.grid()\n",
    "\n",
    "plt.title(\"Curva de aprendizaje - Árbol de Decisión\")\n",
    "plt.legend(loc = \"best\")\n",
    "plt.xlabel(\"Cantidad de Ejemplos de Entrenamiento\")\n",
    "plt.ylabel(\"Precisión\")\n",
    "plt.show()\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[139]:\n",
    "\n",
    "\n",
    "print(\"Profundidad del Árbol\")\n",
    "ad.tree_.max_depth\n",
    "\n",
    "\n",
    "# In[140]:\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 30))\n",
    "\n",
    "tree.plot_tree(ad.fit(X, y)) \n",
    "plt.title(\"Árbol de Decisión - Conjunto Puro\", fontsize = 60)\n",
    "plt.show()\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[141]:\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 30))\n",
    "\n",
    "tree.plot_tree(ad.fit(X_test, y_test)) \n",
    "plt.title(\"Árbol de Decisión - PRUEBA\", fontsize =60)\n",
    "plt.show()\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[142]:\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 30))\n",
    "\n",
    "tree.plot_tree(ad.fit(X_train, y_train)) \n",
    "plt.title(\"Árbol de Decisión - ENTRENAMIENTO\", fontsize = 60)\n",
    "plt.show()\n",
    "print(\"--------------------------------------------------------------------------------------------------------------------------------------------------------------------\\n\\n\")\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "print(\"Proyecto Elaborado por:\\nAbraham Flores Basilio\")\n",
    "print(\"Repositorio: https://github.com/AbrahamFB/Miner-a-de-Datos\")\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
