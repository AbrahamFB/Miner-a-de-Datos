{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c6ea25c6acc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# In[1]:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"PATH\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpathsep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'C:/Program Files (x86)/Graphviz2.38/bin/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "#  **Ensamble básico de clasificadores**\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold # import KFold\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import graphviz\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import random\n",
    "import decimal\n",
    "import seaborn as sb\n",
    "\n",
    "\n",
    "# **Creación del en encabezado**\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "#https://estrategiastrading.com/widgets-interactivos-en-python-ipywidgets/\n",
    "archivo=input(\"Ingresa el nombre del archivo(conjunto de datos)\")\n",
    "file=open(archivo,\"r\")\n",
    "nElementos=int(file.readline())\n",
    "nAtributos=int(file.readline())\n",
    "nClases=int(file.readline())\n",
    "columns=[]\n",
    "atributos=[]\n",
    "print(nAtributos)\n",
    "type(nAtributos)\n",
    "for i in range (1,nAtributos+1):\n",
    "    columns.append(\"x\"+str(i))\n",
    "    atributos.append(\"x\"+str(i))\n",
    "columns.append(\"Clases\")\n",
    "\n",
    "\n",
    "# **Lectura del archivo**\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "cd=pd.read_csv(archivo,skiprows=lambda x: x<3,names=columns)\n",
    "cd.head()\n",
    "\n",
    "\n",
    "# **Escalando los datos**\n",
    "\n",
    "# In[20]:\n",
    "\n",
    "\n",
    "x=cd.loc[:,atributos].values\n",
    "y=cd.loc[:,'Clases'].values\n",
    "x=StandardScaler().fit_transform(x)\n",
    "pd.DataFrame(data=x,columns=atributos).head()\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "dimensiones=int(input(\"Ingresa los numeros de dimensiones a considerar\"))\n",
    "dimTargets=[]\n",
    "for i in range (1,dimensiones+1):\n",
    "    dimTargets.append('Componente principal '+str(i))\n",
    "pca = PCA(n_components=dimensiones)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = pd.DataFrame(data = principalComponents\n",
    "             , columns = dimTargets)\n",
    "finalDf = pd.concat([principalDf, cd[['Clases']]], axis = 1)\n",
    "finalDf.head(5)\n",
    "\n",
    "\n",
    "# **Si es posible se crea la gráfica de los componente principales si se obtienen 2 dimensioens**\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "\n",
    "targets = [0,1,2,3,4,5,6]\n",
    "if dimensiones==2:\n",
    "    fig = plt.figure(figsize = (8,8))\n",
    "    ax = fig.add_subplot(1,1,1) \n",
    "    ax.set_xlabel('Componente principal 1', fontsize = 15)\n",
    "    ax.set_ylabel('Componente principal 2', fontsize = 15)\n",
    "    ax.set_title('PCA 2 Componentes', fontsize = 20)\n",
    "\n",
    "\n",
    "    \n",
    "    colors = ['green','grey','blue','red','brown','pink','yellow']\n",
    "    for target, color in zip(targets,colors):\n",
    "        indicesToKeep = finalDf['Clases'] == target\n",
    "        ax.scatter(finalDf.loc[indicesToKeep, 'Componente principal 1']\n",
    "                   , finalDf.loc[indicesToKeep, 'Componente principal 2']\n",
    "\n",
    "                   , s = 20)\n",
    "    ax.legend(targets)\n",
    "    ax.grid()\n",
    "\n",
    "\n",
    "# **Naive Bayes**\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "import seaborn as sb\n",
    "X = principalComponents\n",
    "pliegues=int(input(\"Ingresa el número de pliegues a considerar\"))\n",
    "clasificadorNB = GaussianNB()\n",
    "predict=cross_val_predict(clasificadorNB,X,y,cv=pliegues)\n",
    "scores = cross_validate(clasificadorNB, X, y, cv=pliegues,\n",
    "                        scoring=('accuracy'),\n",
    "                        return_train_score=True)\n",
    "print(\"\\nPorcentaje de exactitud {0:.2f} %\".format(np.mean(scores['test_score'])*100))\n",
    "print(\"Error {}\".format(((y != predict).sum())/nElementos))\n",
    "print(\"Total de Muestras en Test: {}\\nFallos: {}\"\n",
    "      .format(\n",
    "          nElementos,\n",
    "          (y != predict).sum()\n",
    "))\n",
    "\n",
    "matriz=confusion_matrix(y,predict)\n",
    "print(\"Matriz de confusión:\\n\",matriz)\n",
    "#sns.heatmap(matriz.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "#            xticklabels=targets, yticklabels=targets)\n",
    "#plt.xlabel('Clases reales')\n",
    "#plt.ylabel('Predicción');\n",
    "#Gráfica de dispersión\n",
    "import random\n",
    "import decimal\n",
    "predicciones=[]\n",
    "for i in predict:\n",
    "    j=random.triangular(-.1,.1)\n",
    "    j=round(j,3)\n",
    "    predicciones.append(i+j)\n",
    "\n",
    "real = pd.DataFrame(data=y,columns =['Clases reales'])\n",
    "clases = pd.DataFrame(data=y,columns =['Clases'])\n",
    "predecidas = pd.DataFrame(data=predicciones,columns=['Predicción'])\n",
    "finalDf = pd.concat([real,predecidas,clases], axis = 1)\n",
    "plt.title('Gráfica de dispersión ')\n",
    "grafico=sb.stripplot(x = \"Clases reales\", y = \"Predicción\", hue=\"Clases\",data = finalDf,jitter=.1,linewidth=1)\n",
    "grafico.grid()\n",
    "#Curva de aprendizaje\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=clasificadorNB,\n",
    "                        X=X, y=y, \n",
    "                        cv=pliegues)\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "plt.plot(train_sizes, train_mean, color='r', marker='o', markersize=5,\n",
    "         label='entrenamiento')\n",
    "plt.fill_between(train_sizes, train_mean + train_std, \n",
    "                 train_mean - train_std, alpha=0.15, color='r')\n",
    "plt.plot(train_sizes, test_mean, color='b', linestyle='--', \n",
    "         marker='s', markersize=5, label='evaluacion')\n",
    "plt.fill_between(train_sizes, test_mean + test_std, \n",
    "                 test_mean - test_std, alpha=0.15, color='b')\n",
    "plt.grid()\n",
    "plt.title('Curva de aprendizaje de Naive Bayes ')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('Cantidad de ejemplos de entrenamiento')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# **Árbol de decisión**\n",
    "\n",
    "# In[24]:\n",
    "\n",
    "\n",
    "deep=int(input(\"Ingresa la maxima profundidad del árbol\"))\n",
    "arbol=DecisionTreeClassifier(criterion='entropy', max_depth=deep)\n",
    "predict=cross_val_predict(arbol,x,y,cv=pliegues)\n",
    "scores = cross_validate(arbol, x, y, cv=pliegues,\n",
    "                        scoring=('accuracy'),\n",
    "                        return_train_score=True,return_estimator=True)\n",
    "\n",
    "print(\"\\nPorcentaje de exactitud {0:.2f} %\".format(np.mean(scores['test_score'])*100))\n",
    "print(\"Error {}\".format(((y != predict).sum())/nElementos))\n",
    "print(\"Total de Muestras en Test: {}\\nFallos: {}\"\n",
    "      .format(\n",
    "          nElementos,\n",
    "          (y != predict).sum()\n",
    "))\n",
    "\n",
    "matriz=confusion_matrix(y,predict)\n",
    "print(\"Matriz de confusión:\\n\",matriz)\n",
    "#sns.heatmap(matriz.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "#            xticklabels=targets, yticklabels=targets)\n",
    "#plt.xlabel('Clases reales')\n",
    "#plt.ylabel('Predicción');\n",
    "#Gráfica de dispersión\n",
    "import random\n",
    "import decimal\n",
    "predicciones=[]\n",
    "for i in predict:\n",
    "    j=random.triangular(-.1,.1)\n",
    "    j=round(j,3)\n",
    "    predicciones.append(i+j)\n",
    "\n",
    "real = pd.DataFrame(data=y,columns =['Clases reales'])\n",
    "clases = pd.DataFrame(data=y,columns =['Clases'])\n",
    "predecidas = pd.DataFrame(data=predicciones,columns=['Predicción'])\n",
    "finalDf = pd.concat([real,predecidas,clases], axis = 1)\n",
    "plt.title('Gráfica de dispersión ')\n",
    "grafico=sb.stripplot(x = \"Clases reales\", y = \"Predicción\", hue=\"Clases\",data = finalDf,jitter=.1,linewidth=1)\n",
    "grafico.grid()\n",
    "#Curva de aprendizaje\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=arbol,\n",
    "                        X=x, y=y, \n",
    "                        cv=pliegues)\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "\n",
    "# **Curva de aprendizaje y el árbol de decisición**\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "plt.plot(train_sizes, train_mean, color='r', marker='o', markersize=5,\n",
    "         label='entrenamiento')\n",
    "plt.fill_between(train_sizes, train_mean + train_std, \n",
    "                 train_mean - train_std, alpha=0.15, color='r')\n",
    "plt.plot(train_sizes, test_mean, color='b', linestyle='--', \n",
    "         marker='s', markersize=5, label='evaluacion')\n",
    "plt.fill_between(train_sizes, test_mean + test_std, \n",
    "                 test_mean - test_std, alpha=0.15, color='b')\n",
    "plt.grid()\n",
    "plt.title('Curva de aprendizaje de Árbol de desición ')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('Cantidad de ejemplos de entrenamiento')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()\n",
    "\n",
    "kf = KFold(n_splits=10) # Define the split - into 2 folds  # returns the number of splitting iterations in the cross-validator\n",
    "scor=[]\n",
    "for train_index, test_index in kf.split(x):\n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    arbol.fit(X_train,y_train)\n",
    "    scor.append(arbol.score(X_train,y_train))\n",
    "export_graphviz(arbol, out_file='arbol.dot', class_names=['0','1','2','3','4','5','6'],\n",
    "                feature_names=atributos, impurity=False, filled=True)\n",
    "with open('arbol.dot') as f:\n",
    "    dot_graph=f.read()\n",
    "graphviz.Source(dot_graph)\n",
    "\n",
    "\n",
    "# **K-vecinos más cercanos**\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "k=int(input(\"Ingresa los K vecinos para usar\"))\n",
    "print(k)\n",
    "knn = KNeighborsClassifier(n_neighbors=k)\n",
    "predict=cross_val_predict(knn,X,y,cv=pliegues)\n",
    "scores = cross_validate(knn, X, y, cv=pliegues,\n",
    "                        scoring=('accuracy'),\n",
    "                        return_train_score=True)\n",
    "print(\"\\nPorcentaje de exactitud {0:.2f} %\".format(np.mean(scores['test_score'])*100))\n",
    "print(\"Porcentaje de error {}\".format(nElementos/((y != predict).sum())))\n",
    "print(\"Total de Muestras en Test: {}\\nFallos: {}\"\n",
    "      .format(\n",
    "          nElementos,\n",
    "          (y != predict).sum()\n",
    "))\n",
    "\n",
    "matriz=confusion_matrix(y,predict)\n",
    "print(\"Matriz de confusión:\\n\",matriz)\n",
    "#sns.heatmap(matriz.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "#            xticklabels=targets, yticklabels=targets)\n",
    "#plt.xlabel('Clases reales')\n",
    "#plt.ylabel('Predicción');\n",
    "#Gráfica de dispersión\n",
    "import random\n",
    "import decimal\n",
    "predicciones=[]\n",
    "for i in predict:\n",
    "    j=random.triangular(-.1,.1)\n",
    "    j=round(j,3)\n",
    "    predicciones.append(i+j)\n",
    "\n",
    "real = pd.DataFrame(data=y,columns =['Clases reales'])\n",
    "clases = pd.DataFrame(data=y,columns =['Clases'])\n",
    "predecidas = pd.DataFrame(data=predicciones,columns=['Predicción'])\n",
    "finalDf = pd.concat([real,predecidas,clases], axis = 1)\n",
    "plt.title('Gráfica de dispersión ')\n",
    "grafico=sb.stripplot(x = \"Clases reales\", y = \"Predicción\", hue=\"Clases\",data = finalDf,jitter=.1,linewidth=1)\n",
    "grafico.grid()\n",
    "#Curva de aprendizaje\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=knn,\n",
    "                        X=X, y=y, \n",
    "                        cv=pliegues)\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "\n",
    "# **Curva de aprendizaje de K-vecinos más cercanos**\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "\n",
    "plt.plot(train_sizes, train_mean, color='r', marker='o', markersize=5,\n",
    "         label='entrenamiento')\n",
    "plt.fill_between(train_sizes, train_mean + train_std, \n",
    "                 train_mean - train_std, alpha=0.15, color='r')\n",
    "plt.plot(train_sizes, test_mean, color='b', linestyle='--', \n",
    "         marker='s', markersize=5, label='evaluacion')\n",
    "plt.fill_between(train_sizes, test_mean + test_std, \n",
    "                 test_mean - test_std, alpha=0.15, color='b')\n",
    "plt.grid()\n",
    "plt.title('Curva de aprendizaje de k-vecinos más cercanos ')\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('Cantidad de ejemplos de entrenamiento')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# In[37]:\n",
    "\n",
    "\n",
    "from sklearn.ensemble import  VotingClassifier\n",
    "eclf1 = VotingClassifier(estimators=[\n",
    "        ('NB', clasificadorNB), ('a', arbol), ('knn', knn)], voting='hard')\n",
    "scores = cross_validate(eclf1, X, y, cv=pliegues,\n",
    "                        scoring=('accuracy'),\n",
    "                        return_train_score=True)\n",
    "predict=cross_val_predict(knn,X,y,cv=pliegues)\n",
    "print(\"\\nPorcentaje de exactitud {0:.2f} %\".format(np.mean(scores['test_score'])*100))\n",
    "print(\"Porcentaje de error {}\".format(nElementos/((y != predict).sum())))\n",
    "print(\"Total de Muestras en Test: {}\\nFallos: {}\"\n",
    "      .format(\n",
    "          nElementos,\n",
    "          (y != predict).sum()\n",
    "))\n",
    "\n",
    "matriz=confusion_matrix(y,predict)\n",
    "print(\"Matriz de confusión:\\n\",matriz)\n",
    "#sns.heatmap(matriz.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "#            xticklabels=targets, yticklabels=targets)\n",
    "#plt.xlabel('Clases reales')\n",
    "#plt.ylabel('Predicción');\n",
    "#Gráfica de dispersión\n",
    "import random\n",
    "import decimal\n",
    "predicciones=[]\n",
    "for i in predict:\n",
    "    j=random.triangular(-.1,.1)\n",
    "    j=round(j,3)\n",
    "    predicciones.append(i+j)\n",
    "\n",
    "real = pd.DataFrame(data=y,columns =['Clases reales'])\n",
    "clases = pd.DataFrame(data=y,columns =['Clases'])\n",
    "predecidas = pd.DataFrame(data=predicciones,columns=['Predicción'])\n",
    "finalDf = pd.concat([real,predecidas,clases], axis = 1)\n",
    "plt.title('Gráfica de dispersión ')\n",
    "grafico=sb.stripplot(x = \"Clases reales\", y = \"Predicción\", hue=\"Clases\",data = finalDf,jitter=.1,linewidth=1)\n",
    "grafico.grid()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
